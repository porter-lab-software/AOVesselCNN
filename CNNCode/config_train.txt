[prep data type]
Training = True
TestingKnown = True

[data paths]
#To train network include: image_path, path_local, validation_image_path, specfic hdf5 file names

image_path = /brazos/porter/github/DataSet Folders_Images/TrainingDataSet/
validation_image_path = /brazos/porter/github/DataSet Folders_Images/TestingDataSet/
path_local =  /brazos/porter/github/DataSet Folders_HDF5/standard/

train_imgs_original = standard_imgs_train.hdf5
train_combo = standard_Combos_train.hdf5
test_imgs_original = standard_imgs_test.hdf5
test_combo = standard_Combos_test.hdf5
trained_cnn = trained_best_weights.h5

[experiment name]
#Identifier for specific run (output folder)
name = trained

[data attributes]
#Dimensions of the patches extracted from the full images
patch_height = 128
patch_width = 128


[training settings]
#if patches are extracted only inside the field of view:
inside_FOV = True
stride_height = 64
stride_width = 64
#Number of training epochs
N_epochs = 350
batch_size = 64

# enable nohup so remote task continues if logout
nohup = True


[testing settings]
#number of full images for the test
full_images_to_test = 14
#How many original-groundTruth-prediction images are visualized in each image
N_group_visual = 14
#Only if average_mode==True. Stride for patch extraction, lower value require more patches to be predicted
stride_height = 32
stride_width = 32

